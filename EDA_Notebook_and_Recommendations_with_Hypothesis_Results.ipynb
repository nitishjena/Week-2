{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2fd9a2c",
   "metadata": {},
   "source": [
    "\n",
    "# Exploratory Data Analysis (EDA) Notebook\n",
    "\n",
    "This notebook presents a thorough exploration and analysis of cab company data for investment consideration by XYZ. \n",
    "The analysis covers data understanding, data quality assessment, integration strategy, and hypothesis testing. \n",
    "The goal is to deliver actionable insights on each company’s performance, customer demographics, and market demand trends, \n",
    "helping XYZ make an informed investment decision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914bc510",
   "metadata": {},
   "source": [
    "\n",
    "# Data Understanding\n",
    "In this section, we begin by loading and exploring each of the four datasets provided. \n",
    "We aim to gain an initial understanding of the structure, key fields, and types of data available \n",
    "in each dataset to inform our subsequent analysis and integration steps.\n",
    "\n",
    "### Steps Taken\n",
    "- We load each dataset and examine a few rows to get a sense of the data and its structure.\n",
    "- We make notes of the fields available in each dataset and their relevance to our business questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4d251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "cab_data = pd.read_csv('/mnt/data/Cab_Data.csv')\n",
    "transaction_data = pd.read_csv('/mnt/data/Transaction_ID.csv')\n",
    "customer_data = pd.read_csv('/mnt/data/Customer_ID.csv')\n",
    "city_data = pd.read_csv('/mnt/data/City.csv')\n",
    "\n",
    "# Display the first few rows of each dataset to understand structure\n",
    "cab_data_head = cab_data.head()\n",
    "transaction_data_head = transaction_data.head()\n",
    "customer_data_head = customer_data.head()\n",
    "city_data_head = city_data.head()\n",
    "\n",
    "cab_data_head, transaction_data_head, customer_data_head, city_data_head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc3ad4c",
   "metadata": {},
   "source": [
    "\n",
    "# Data Cleaning\n",
    "Ensuring data quality is essential for reliable analysis. This section identifies and handles \n",
    "potential issues such as missing values and duplicate records that could impact our analysis.\n",
    "\n",
    "### Steps Taken\n",
    "- We perform a quality check on each dataset for missing values and duplicates.\n",
    "- Summary results of the checks are displayed, allowing us to see if any data cleaning actions are required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b734ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Checking for missing values and duplicates in each dataset\n",
    "\n",
    "# Function to check for missing values and duplicates in a DataFrame\n",
    "def data_quality_check(df, name):\n",
    "    missing_values = df.isnull().sum()\n",
    "    duplicates = df.duplicated().sum()\n",
    "    return pd.DataFrame({\n",
    "        'Dataset': name,\n",
    "        'Total Rows': [df.shape[0]],\n",
    "        'Total Columns': [df.shape[1]],\n",
    "        'Missing Values': [missing_values.sum()],\n",
    "        'Duplicates': [duplicates]\n",
    "    })\n",
    "\n",
    "# Perform quality check for each dataset\n",
    "quality_checks = pd.concat([\n",
    "    data_quality_check(cab_data, \"Cab_Data\"),\n",
    "    data_quality_check(transaction_data, \"Transaction_ID\"),\n",
    "    data_quality_check(customer_data, \"Customer_ID\"),\n",
    "    data_quality_check(city_data, \"City\")\n",
    "])\n",
    "\n",
    "quality_checks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e90aa1d",
   "metadata": {},
   "source": [
    "\n",
    "# Data Integration\n",
    "The objective here is to combine the datasets into a master dataset, linking relevant fields across \n",
    "the files. This integrated dataset will serve as the foundation for our analysis.\n",
    "\n",
    "### Steps Taken\n",
    "- Convert date fields into a standard format to make time-based analysis possible.\n",
    "- Merge the datasets in the following order to form the master dataset:\n",
    "  - **Cab_Data** with **Transaction_ID** (linking transactions with customers and payment details)\n",
    "  - The resulting data with **Customer_ID** (adding customer demographic information)\n",
    "  - Finally, merge with **City** data (providing city-specific population and user data)\n",
    "- The merged master dataset now contains comprehensive information for each transaction, ready for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d1127",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Converting date field in Cab_Data to readable format\n",
    "cab_data['Date of Travel'] = pd.to_datetime('1899-12-30') + pd.to_timedelta(cab_data['Date of Travel'], 'D')\n",
    "\n",
    "# Step-by-Step Merging to Create Master Data\n",
    "cab_transaction_merged = pd.merge(cab_data, transaction_data, on='Transaction ID', how='left')\n",
    "cab_customer_merged = pd.merge(cab_transaction_merged, customer_data, on='Customer ID', how='left')\n",
    "master_data = pd.merge(cab_customer_merged, city_data, on='City', how='left')\n",
    "\n",
    "# Display the first few rows of the master dataset to confirm integration\n",
    "master_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae135766",
   "metadata": {},
   "source": [
    "\n",
    "# Outlier Detection\n",
    "Outliers can often skew analysis, so we perform a detection process on key numerical columns \n",
    "to identify any extreme values that could impact our results.\n",
    "\n",
    "### Steps Taken\n",
    "- Using the IQR (Interquartile Range) method, we check for outliers in fields like `KM Travelled`, \n",
    "  `Price Charged`, `Cost of Trip`, and `Income (USD/Month)`.\n",
    "- A summary is displayed, showing the number of detected outliers in each field.\n",
    "- Outliers are noted for potential exclusion or further investigation, particularly in the `Price Charged` field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1086af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Outlier Detection for Key Numeric Columns\n",
    "\n",
    "# Function to detect outliers based on IQR\n",
    "def detect_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return len(df[(df[column] < lower_bound) | (df[column] > upper_bound)])\n",
    "\n",
    "# Detecting outliers in relevant columns\n",
    "outlier_summary = {\n",
    "    'Column': ['KM Travelled', 'Price Charged', 'Cost of Trip', 'Income (USD/Month)'],\n",
    "    'Number of Outliers': [\n",
    "        detect_outliers(master_data, 'KM Travelled'),\n",
    "        detect_outliers(master_data, 'Price Charged'),\n",
    "        detect_outliers(master_data, 'Cost of Trip'),\n",
    "        detect_outliers(master_data, 'Income (USD/Month)')\n",
    "    ]\n",
    "}\n",
    "pd.DataFrame(outlier_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86217f4",
   "metadata": {},
   "source": [
    "\n",
    "# EDA Recommendations and Hypothesis Results\n",
    "\n",
    "This section presents the findings of the exploratory data analysis based on the hypotheses we set out to investigate. \n",
    "Each hypothesis includes a summary of the approach taken, the key findings, and visuals to support the results. \n",
    "The section concludes with actionable recommendations for XYZ’s investment considerations.\n",
    "\n",
    "## Hypothesis 1: Seasonality in Cab Usage and Revenue\n",
    "\n",
    "### Approach\n",
    "We wanted to understand if there is a predictable seasonality in cab usage and revenue, which could impact \n",
    "both resource allocation and strategic planning. We aggregated trip data by month and visualized it over time \n",
    "to observe if any patterns consistently emerge throughout the year.\n",
    "\n",
    "### Key Findings\n",
    "The analysis shows a seasonal trend, with certain months seeing a noticeable increase in trip volume and revenue. \n",
    "These peaks likely align with holidays, seasonal travel demands, or local events that boost cab usage.\n",
    "\n",
    "### Supporting Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33586364",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Monthly Trend Analysis for Total Trips and Revenue\n",
    "master_data['Year'] = master_data['Date of Travel'].dt.year\n",
    "master_data['Month'] = master_data['Date of Travel'].dt.month\n",
    "\n",
    "monthly_trend = master_data.groupby(['Year', 'Month']).agg(\n",
    "    total_trips=('Transaction ID', 'count'),\n",
    "    total_revenue=('Price Charged', 'sum')\n",
    ").reset_index()\n",
    "monthly_trend['Month-Year'] = pd.to_datetime(monthly_trend[['Year', 'Month']].assign(Day=1))\n",
    "\n",
    "# Plotting Trip and Revenue Trends\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "ax1.plot(monthly_trend['Month-Year'], monthly_trend['total_trips'], label='Total Trips', marker='o')\n",
    "ax2.plot(monthly_trend['Month-Year'], monthly_trend['total_revenue'], label='Total Revenue', marker='o', color='orange')\n",
    "\n",
    "ax1.set_title(\"Monthly Trend of Total Trips\")\n",
    "ax2.set_title(\"Monthly Trend of Total Revenue\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca4d8b8",
   "metadata": {},
   "source": [
    "\n",
    "## Hypothesis 2: Customer Demographics and Usage Patterns\n",
    "\n",
    "### Approach\n",
    "To see if customer characteristics like age and income affect usage, we examined demographic data. \n",
    "We particularly focused on high-frequency users, as these customers are more likely to bring consistent revenue. \n",
    "The data was segmented by age and income to observe if particular customer profiles are linked to higher usage.\n",
    "\n",
    "### Key Findings\n",
    "Both companies serve customers from a wide range of ages and income levels. However, high-frequency users tend to \n",
    "fall within certain age and income brackets, hinting that targeting these groups could enhance customer loyalty.\n",
    "\n",
    "### Supporting Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12036f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# High-Frequency Customer Segment Attributes\n",
    "\n",
    "# Aggregating demographic data by company to see average age and income for top customers (based on frequency of trips)\n",
    "customer_segment_attributes = master_data.groupby(['Company', 'Customer ID']).agg(\n",
    "    total_trips=('Transaction ID', 'count'),\n",
    "    avg_age=('Age', 'mean'),\n",
    "    avg_income=('Income (USD/Month)', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# High-frequency customers (top 20% of total trips per company)\n",
    "high_frequency_threshold = customer_segment_attributes.groupby('Company')['total_trips'].quantile(0.8)\n",
    "high_frequency_customers = customer_segment_attributes[\n",
    "    (customer_segment_attributes['Company'] == 'Pink Cab') & \n",
    "    (customer_segment_attributes['total_trips'] >= high_frequency_threshold['Pink Cab'])\n",
    "].append(\n",
    "    customer_segment_attributes[\n",
    "        (customer_segment_attributes['Company'] == 'Yellow Cab') & \n",
    "        (customer_segment_attributes['total_trips'] >= high_frequency_threshold['Yellow Cab'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Summarizing average attributes for high-frequency customers by company\n",
    "high_frequency_summary = high_frequency_customers.groupby('Company').agg(\n",
    "    avg_age=('avg_age', 'mean'),\n",
    "    avg_income=('avg_income', 'mean'),\n",
    "    avg_trip_count=('total_trips', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "high_frequency_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee61ef4",
   "metadata": {},
   "source": [
    "\n",
    "## Hypothesis 3: Does Profit Increase with Customer Volume?\n",
    "\n",
    "### Approach\n",
    "To investigate if profitability scales with customer volume, we compared the number of trips to profit margins. \n",
    "By plotting these two variables, we could observe if higher customer numbers directly correspond to higher profit levels.\n",
    "\n",
    "### Key Findings\n",
    "A positive correlation between trip count and profit was observed, suggesting that as the number of trips increases, \n",
    "profit also rises. However, the relationship is not perfectly proportional, likely due to variations in trip costs \n",
    "and pricing structures.\n",
    "\n",
    "### Supporting Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852904f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scatter plot of total trips vs. total profit to analyze correlation\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "for company in company_monthly_performance['Company'].unique():\n",
    "    data = company_monthly_performance[company_monthly_performance['Company'] == company]\n",
    "    ax.scatter(data['total_trips'], data['total_profit'], label=company, alpha=0.6)\n",
    "\n",
    "ax.set_title('Correlation between Trip Count and Profit by Company')\n",
    "ax.set_xlabel('Total Trips')\n",
    "ax.set_ylabel('Total Profit (USD)')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf13e0d",
   "metadata": {},
   "source": [
    "\n",
    "# Actionable Insights and Recommendations\n",
    "\n",
    "Based on the data analysis, here are several recommendations for XYZ to consider in their investment decision:\n",
    "\n",
    "1. **Market Strength**: Yellow Cab shows stronger financial performance, with higher trip volumes and revenue. \n",
    "   This company could be a favorable investment due to its established market share and profitability.\n",
    "\n",
    "2. **Target Demographics**: Both companies have potential to increase revenue by focusing on high-frequency customer \n",
    "   segments, specifically targeting age and income groups that are more likely to use the service regularly.\n",
    "\n",
    "3. **Seasonal Demand Management**: The identified seasonal trends can inform operational planning and marketing efforts, \n",
    "   ensuring resources are allocated optimally during peak demand periods.\n",
    "\n",
    "### Final Recommendation\n",
    "Yellow Cab appears to be the more advantageous choice due to its larger customer base and higher profitability. \n",
    "However, Pink Cab might still offer value if XYZ is interested in tapping into a different segment or growth opportunity.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
